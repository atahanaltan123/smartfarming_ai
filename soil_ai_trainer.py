import json
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler, LabelEncoder
import joblib
import os
from datetime import datetime

class SoilAITrainer:
    def __init__(self, data_path="training_data/soil_analysis_dataset.json"):
        self.data_path = data_path
        self.dataset = None
        self.models = {}
        self.scalers = {}
        self.label_encoders = {}
        self.performance_metrics = {}
        
    def load_dataset(self):
        """Veri setini y√ºkle"""
        try:
            with open(self.data_path, 'r', encoding='utf-8') as f:
                self.dataset = json.load(f)
            print(f"‚úÖ Veri seti y√ºklendi: {len(self.dataset['soil_samples'])} √∂rnek")
            return True
        except Exception as e:
            print(f"‚ùå Veri seti y√ºklenemedi: {e}")
            return False
    
    def prepare_training_data(self):
        """Eƒüitim verilerini hazƒ±rla"""
        if not self.dataset:
            print("‚ùå √ñnce veri seti y√ºklenmeli")
            return None, None
        
        # Veri setini DataFrame'e √ßevir
        samples = []
        for sample in self.dataset['soil_samples']:
            row = {
                'region': sample['region'],
                'climate': sample['climate'],
                'irrigation': sample['irrigation'],
                'pH': sample['soil_values']['pH'],
                'organic_matter': sample['soil_values']['organic_matter'],
                'nitrogen': sample['soil_values']['nitrogen'],
                'phosphorus': sample['soil_values']['phosphorus'],
                'potassium': sample['soil_values']['potassium'],
                'calcium': sample['soil_values']['calcium'],
                'magnesium': sample['soil_values']['magnesium'],
                'iron': sample['soil_values']['iron'],
                'zinc': sample['soil_values']['zinc']
            }
            
            # Her √ºr√ºn i√ßin ayrƒ± satƒ±r olu≈ütur
            for crop, success_data in sample['crop_success'].items():
                crop_row = row.copy()
                crop_row['crop'] = crop
                crop_row['yield_level'] = success_data['yield']
                crop_row['quality'] = success_data['quality']
                crop_row['success_rate'] = success_data['success_rate']
                samples.append(crop_row)
        
        df = pd.DataFrame(samples)
        print(f"‚úÖ Eƒüitim verisi hazƒ±rlandƒ±: {len(df)} satƒ±r")
        
        # Kategorik deƒüi≈ükenleri encode et
        categorical_cols = ['region', 'climate', 'irrigation', 'crop', 'yield_level', 'quality']
        for col in categorical_cols:
            if col in df.columns:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col])
                self.label_encoders[col] = le
        
        # √ñzellikler ve hedef deƒüi≈ükenler
        feature_cols = ['region', 'climate', 'irrigation', 'pH', 'organic_matter', 
                       'nitrogen', 'phosphorus', 'potassium', 'calcium', 'magnesium', 'iron', 'zinc']
        
        X = df[feature_cols]
        y_yield = df['yield_level']
        y_quality = df['quality']
        y_success = df['success_rate']
        
        return X, y_yield, y_quality, y_success
    
    def train_models(self):
        """AI modellerini eƒüit"""
        X, y_yield, y_quality, y_success = self.prepare_training_data()
        
        if X is None:
            return False
        
        # Veriyi eƒüitim ve test olarak b√∂l
        X_train, X_test, y_yield_train, y_yield_test = train_test_split(
            X, y_yield, test_size=0.2, random_state=42
        )
        _, _, y_quality_train, y_quality_test = train_test_split(
            X, y_quality, test_size=0.2, random_state=42
        )
        _, _, y_success_train, y_success_test = train_test_split(
            X, y_success, test_size=0.2, random_state=42
        )
        
        # Veriyi √∂l√ßeklendir
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        self.scalers['features'] = scaler
        
        print("üöÄ Model eƒüitimi ba≈ülƒ±yor...")
        
        # 1. Verim Tahmin Modeli (Classification)
        print("üìä Verim tahmin modeli eƒüitiliyor...")
        yield_model = RandomForestClassifier(n_estimators=100, random_state=42)
        yield_model.fit(X_train_scaled, y_yield_train)
        self.models['yield_predictor'] = yield_model
        
        # 2. Kalite Tahmin Modeli (Classification)
        print("‚≠ê Kalite tahmin modeli eƒüitiliyor...")
        quality_model = RandomForestClassifier(n_estimators=100, random_state=42)
        quality_model.fit(X_train_scaled, y_quality_train)
        self.models['quality_predictor'] = quality_model
        
        # 3. Ba≈üarƒ± Oranƒ± Tahmin Modeli (Regression)
        print("üìà Ba≈üarƒ± oranƒ± tahmin modeli eƒüitiliyor...")
        success_model = RandomForestRegressor(n_estimators=100, random_state=42)
        success_model.fit(X_train_scaled, y_success_train)
        self.models['success_predictor'] = success_model
        
        # Model performanslarƒ±nƒ± deƒüerlendir
        self.evaluate_models(X_test_scaled, y_yield_test, y_quality_test, y_success_test)
        
        return True
    
    def evaluate_models(self, X_test, y_yield_test, y_quality_test, y_success_test):
        """Model performanslarƒ±nƒ± deƒüerlendir"""
        print("\nüìä Model Performans Deƒüerlendirmesi:")
        print("=" * 50)
        
        # Verim tahmin modeli
        yield_pred = self.models['yield_predictor'].predict(X_test)
        yield_accuracy = accuracy_score(y_yield_test, yield_pred)
        print(f"üåæ Verim Tahmin Modeli:")
        print(f"   Doƒüruluk: {yield_accuracy:.3f} ({yield_accuracy*100:.1f}%)")
        
        # Kalite tahmin modeli
        quality_pred = self.models['quality_predictor'].predict(X_test)
        quality_accuracy = accuracy_score(y_quality_test, quality_pred)
        print(f"‚≠ê Kalite Tahmin Modeli:")
        print(f"   Doƒüruluk: {quality_accuracy:.3f} ({quality_accuracy*100:.1f}%)")
        
        # Ba≈üarƒ± oranƒ± tahmin modeli
        success_pred = self.models['success_predictor'].predict(X_test)
        success_mse = mean_squared_error(y_success_test, success_pred)
        success_r2 = r2_score(y_success_test, success_pred)
        print(f"üìà Ba≈üarƒ± Oranƒ± Tahmin Modeli:")
        print(f"   MSE: {success_mse:.4f}")
        print(f"   R¬≤: {success_r2:.3f} ({success_r2*100:.1f}%)")
        
        # Cross-validation scores (only if we have enough data)
        print("\nüîÑ Cross-Validation Sonu√ßlarƒ±:")
        min_samples_for_cv = 10
        if len(X_test) >= min_samples_for_cv:
            for name, model in self.models.items():
                if 'predictor' in name:
                    try:
                        if 'success' in name:
                            # Regression model
                            cv_scores = cross_val_score(model, X_test, y_success_test, cv=min(3, len(X_test)//2), scoring='r2')
                            print(f"   {name}: R¬≤ = {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
                        else:
                            # Classification model
                            cv_scores = cross_val_score(model, X_test, 
                                                     y_yield_test if 'yield' in name else y_quality_test, 
                                                     cv=min(3, len(X_test)//2), scoring='accuracy')
                            print(f"   {name}: Accuracy = {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
                    except Exception as e:
                        print(f"   {name}: Cross-validation hatasƒ± - {e}")
        else:
            print(f"   ‚ö†Ô∏è Cross-validation i√ßin yeterli veri yok (minimum {min_samples_for_cv} gerekli, mevcut: {len(X_test)})")
        
        # Performans metriklerini sakla
        self.performance_metrics = {
            'yield_accuracy': yield_accuracy,
            'quality_accuracy': quality_accuracy,
            'success_mse': success_mse,
            'success_r2': success_r2,
            'test_samples': len(X_test)
        }
    
    def predict_crop_success(self, soil_data):
        """Yeni toprak verisi i√ßin √ºr√ºn ba≈üarƒ±sƒ±nƒ± tahmin et"""
        if not self.models:
            print("‚ùå Modeller hen√ºz eƒüitilmemi≈ü")
            return None
        
        try:
            # Veriyi hazƒ±rla
            features = np.array([
                soil_data['region'],
                soil_data['climate'],
                soil_data['irrigation'],
                soil_data['pH'],
                soil_data['organic_matter'],
                soil_data['nitrogen'],
                soil_data['phosphorus'],
                soil_data['potassium'],
                soil_data['calcium'],
                soil_data['magnesium'],
                soil_data['iron'],
                soil_data['zinc']
            ]).reshape(1, -1)
            
            # √ñl√ßeklendir
            features_scaled = self.scalers['features'].transform(features)
            
            # Tahminler yap
            yield_pred = self.models['yield_predictor'].predict(features_scaled)[0]
            quality_pred = self.models['quality_predictor'].predict(features_scaled)[0]
            success_pred = self.models['success_predictor'].predict(features_scaled)[0]
            
            # Sonu√ßlarƒ± decode et
            yield_level = self.label_encoders['yield_level'].inverse_transform([yield_pred])[0]
            quality = self.label_encoders['quality'].inverse_transform([quality_pred])[0]
            
            return {
                'yield_level': yield_level,
                'quality': quality,
                'success_rate': float(success_pred),
                'confidence': self.calculate_confidence(success_pred)
            }
            
        except Exception as e:
            print(f"‚ùå Tahmin hatasƒ±: {e}")
            return None
    
    def calculate_confidence(self, success_rate):
        """Ba≈üarƒ± oranƒ±na g√∂re g√ºven skoru hesapla"""
        if success_rate >= 0.8:
            return "Y√ºksek"
        elif success_rate >= 0.6:
            return "Orta"
        elif success_rate >= 0.4:
            return "D√º≈ü√ºk"
        else:
            return "√áok D√º≈ü√ºk"
    
    def save_models(self, save_dir="trained_models"):
        """Eƒüitilmi≈ü modelleri kaydet"""
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Modelleri kaydet
        for name, model in self.models.items():
            model_path = os.path.join(save_dir, f"{name}_{timestamp}.joblib")
            joblib.dump(model, model_path)
            print(f"üíæ Model kaydedildi: {model_path}")
        
        # Scaler'larƒ± kaydet
        for name, scaler in self.scalers.items():
            scaler_path = os.path.join(save_dir, f"{name}_scaler_{timestamp}.joblib")
            joblib.dump(scaler, scaler_path)
            print(f"üíæ Scaler kaydedildi: {scaler_path}")
        
        # Label encoder'larƒ± kaydet
        for name, encoder in self.label_encoders.items():
            encoder_path = os.path.join(save_dir, f"{name}_encoder_{timestamp}.joblib")
            joblib.dump(encoder, encoder_path)
            print(f"üíæ Encoder kaydedildi: {encoder_path}")
        
        # Performans metriklerini kaydet
        metrics_path = os.path.join(save_dir, f"performance_metrics_{timestamp}.json")
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(self.performance_metrics, f, indent=2, ensure_ascii=False)
        print(f"üíæ Performans metrikleri kaydedildi: {metrics_path}")
    
    def generate_test_report(self):
        """Test raporu olu≈ütur"""
        if not self.performance_metrics:
            print("‚ùå Performans metrikleri mevcut deƒüil")
            return
        
        report = {
            "model_training_summary": {
                "timestamp": datetime.now().isoformat(),
                "total_models": len(self.models),
                "test_samples": self.performance_metrics['test_samples']
            },
            "model_performance": {
                "yield_predictor": {
                    "type": "Classification",
                    "metric": "Accuracy",
                    "value": self.performance_metrics['yield_accuracy'],
                    "percentage": f"{self.performance_metrics['yield_accuracy']*100:.1f}%"
                },
                "quality_predictor": {
                    "type": "Classification",
                    "metric": "Accuracy",
                    "value": self.performance_metrics['quality_accuracy'],
                    "percentage": f"{self.performance_metrics['quality_accuracy']*100:.1f}%"
                },
                "success_predictor": {
                    "type": "Regression",
                    "metric": "R¬≤ Score",
                    "value": self.performance_metrics['success_r2'],
                    "percentage": f"{self.performance_metrics['success_r2']*100:.1f}%"
                }
            },
            "recommendations": {
                "model_quality": "Y√ºksek" if self.performance_metrics['yield_accuracy'] > 0.8 else "Orta",
                "data_quality": "ƒ∞yi" if self.performance_metrics['test_samples'] > 50 else "Geli≈ütirilebilir",
                "next_steps": [
                    "Daha fazla toprak analiz verisi toplanmalƒ±",
                    "Farklƒ± b√∂lgelerden veri eklenmeli",
                    "Model hiperparametreleri optimize edilmeli"
                ]
            }
        }
        
        # Raporu kaydet
        report_path = f"training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"üìã Test raporu olu≈üturuldu: {report_path}")
        return report

def main():
    """Ana fonksiyon"""
    print("üå± AgriSoilTech - Toprak AI Model Eƒüitimi")
    print("=" * 50)
    
    # Trainer'ƒ± ba≈ülat
    trainer = SoilAITrainer()
    
    # Veri setini y√ºkle
    if not trainer.load_dataset():
        return
    
    # Modelleri eƒüit
    if not trainer.train_models():
        return
    
    # Modelleri kaydet
    trainer.save_models()
    
    # Test raporu olu≈ütur
    trainer.generate_test_report()
    
    # √ñrnek tahmin yap
    print("\nüß™ √ñrnek Tahmin Testi:")
    print("-" * 30)
    
    test_soil = {
        'region': 0,  # Marmara
        'climate': 0,  # Mediterranean
        'irrigation': 1,  # Irrigated
        'pH': 6.8,
        'organic_matter': 2.1,
        'nitrogen': 15,
        'phosphorus': 25,
        'potassium': 180,
        'calcium': 1200,
        'magnesium': 150,
        'iron': 8,
        'zinc': 1.2
    }
    
    prediction = trainer.predict_crop_success(test_soil)
    if prediction:
        print(f"üåæ Tahmin Sonucu:")
        print(f"   Verim Seviyesi: {prediction['yield_level']}")
        print(f"   Kalite: {prediction['quality']}")
        print(f"   Ba≈üarƒ± Oranƒ±: {prediction['success_rate']:.3f}")
        print(f"   G√ºven: {prediction['confidence']}")
    
    print("\n‚úÖ Model eƒüitimi tamamlandƒ±!")

if __name__ == "__main__":
    main()
