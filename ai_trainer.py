import json
import os
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime
from config import Config

class AITrainer:
    """Claude AI modelini √∂zelle≈ütirilmi≈ü veri seti ile eƒüiten sƒ±nƒ±f"""
    
    def __init__(self):
        self.api_key = Config.get_claude_api_key()
        self.api_url = Config.CLAUDE_API_URL
        self.model = Config.CLAUDE_MODEL
        self.headers = {
            "Content-Type": "application/json",
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01"
        }
        
        # Eƒüitim verileri
        self.training_data = []
        self.validation_data = []
        self.test_results = []
        
        # Model performans metrikleri
        self.performance_metrics = {
            "accuracy": 0.0,
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 0.0,
            "total_tests": 0,
            "correct_predictions": 0
        }
    
    def load_training_data(self, data_file: str = "training_dataset.json") -> bool:
        """Eƒüitim veri setini y√ºkler"""
        try:
            if os.path.exists(data_file):
                with open(data_file, 'r', encoding='utf-8') as f:
                    self.training_data = json.load(f)
                print(f"‚úÖ Eƒüitim veri seti y√ºklendi: {len(self.training_data)} √∂rnek")
                return True
            else:
                print(f"‚ùå Eƒüitim veri seti bulunamadƒ±: {data_file}")
                return False
        except Exception as e:
            print(f"Veri y√ºkleme hatasƒ±: {e}")
            return False
    
    def create_custom_prompt(self, plant_type: str, symptoms: List[str], 
                           climate: str = "", season: str = "") -> str:
        """√ñzelle≈ütirilmi≈ü analiz prompt'u olu≈üturur"""
        
        base_prompt = f"""Sen bir uzman tarƒ±m bilimcisi ve bitki hastalƒ±k uzmanƒ±sƒ±n. 
A≈üaƒüƒ±daki bilgileri kullanarak detaylƒ± bir analiz yap:

**Bitki T√ºr√º**: {plant_type}
**G√∂zlemlenen Belirtiler**: {', '.join(symptoms)}
**Mevsim**: {season if season else 'Belirtilmemi≈ü'}
**ƒ∞klim Ko≈üullarƒ±**: {climate if climate else 'Belirtilmemi≈ü'}

L√ºtfen a≈üaƒüƒ±daki formatta detaylƒ± bir analiz ver:

1. **Hastalƒ±k Tespiti**: G√∂r√ºnt√ºde hangi hastalƒ±k belirtileri var?
2. **Hastalƒ±k T√ºr√º**: Fungal, bakteriyel, viral veya zararlƒ± b√∂cek?
3. **≈ûiddet Deƒüerlendirmesi**: D√º≈ü√ºk, orta, y√ºksek veya kritik?
4. **Belirti Analizi**: Her belirtiyi detaylƒ± a√ßƒ±kla
5. **Tedavi √ñnerileri**: Acil ve uzun vadeli √ß√∂z√ºmler
6. **√ñnleyici Tedbirler**: Gelecekte benzer hastalƒ±klarƒ± √∂nleme
7. **Uzman Tavsiyeleri**: Pratik √∂neriler
8. **G√ºvenilirlik Oranƒ±**: Bu analizin g√ºvenilirlik y√ºzdesi

L√ºtfen T√ºrk√ße olarak, √ßift√ßilerin anlayabileceƒüi ≈üekilde yanƒ±tla."""
        
        return base_prompt
    
    def train_with_few_shot_learning(self, plant_type: str, symptoms: List[str], 
                                    expected_disease: str = "") -> Dict[str, Any]:
        """Few-shot learning ile model eƒüitimi"""
        
        try:
            # Eƒüitim veri setinden benzer √∂rnekler bul
            relevant_examples = self._find_relevant_examples(plant_type, symptoms)
            
            # √ñzelle≈ütirilmi≈ü prompt olu≈ütur
            custom_prompt = self.create_custom_prompt(plant_type, symptoms)
            
            # Few-shot learning i√ßin √∂rnekler ekle
            if relevant_examples:
                custom_prompt += "\n\n**Benzer Vaka √ñrnekleri:**\n"
                for i, example in enumerate(relevant_examples[:3], 1):
                    custom_prompt += f"\n√ñrnek {i}: {example['plant_type']} - {example['disease_name']}\n"
                    custom_prompt += f"Belirtiler: {', '.join(example['symptoms'])}\n"
                    custom_prompt += f"Tedavi: {', '.join(example['treatment_methods'])}\n"
            
            # Claude API'ye g√∂nder
            message = {
                "model": self.model,
                "max_tokens": 1500,
                "messages": [
                    {
                        "role": "user",
                        "content": custom_prompt
                    }
                ]
            }
            
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json=message
            )
            
            if response.status_code == 200:
                result = response.json()
                analysis = result["content"][0]["text"]
                
                # Sonucu deƒüerlendir
                evaluation = self._evaluate_prediction(
                    analysis, expected_disease, plant_type, symptoms
                )
                
                return {
                    "success": True,
                    "analysis": analysis,
                    "evaluation": evaluation,
                    "training_examples_used": len(relevant_examples),
                    "model": self.model
                }
            else:
                return {
                    "success": False,
                    "error": f"API Hatasƒ±: {response.status_code}",
                    "details": response.text
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"Eƒüitim hatasƒ±: {str(e)}"
            }
    
    def _find_relevant_examples(self, plant_type: str, symptoms: List[str]) -> List[Dict]:
        """Eƒüitim veri setinden ilgili √∂rnekleri bulur"""
        relevant_examples = []
        
        for example in self.training_data:
            # Bitki t√ºr√º e≈üle≈ümesi - d√ºzeltilmi≈ü
            example_text = example["messages"][0]["content"][0]["text"]
            if plant_type.lower() in example_text.lower():
                # Eksik alanlarƒ± ekle
                example['plant_type'] = plant_type
                example['disease_name'] = "Bilinmeyen Hastalƒ±k"
                example['symptoms'] = symptoms
                example['treatment_methods'] = ["Genel tedavi √∂nerileri"]
                relevant_examples.append(example)
            # Belirti e≈üle≈ümesi
            elif any(symptom.lower() in str(example).lower() for symptom in symptoms):
                # Eksik alanlarƒ± ekle
                example['plant_type'] = plant_type
                example['disease_name'] = "Belirti bazlƒ± hastalƒ±k"
                example['symptoms'] = symptoms
                example['treatment_methods'] = ["Genel tedavi √∂nerileri"]
                relevant_examples.append(example)
        
        # Benzerlik skoruna g√∂re sƒ±rala
        relevant_examples.sort(key=lambda x: self._calculate_similarity_score(
            plant_type, symptoms, x
        ), reverse=True)
        
        return relevant_examples[:5]  # En iyi 5 √∂rnek
    
    def _calculate_similarity_score(self, plant_type: str, symptoms: List[str], 
                                  example: Dict) -> float:
        """Benzerlik skoru hesaplar"""
        score = 0.0
        
        # Bitki t√ºr√º e≈üle≈ümesi
        if plant_type.lower() in str(example).lower():
            score += 0.5
        
        # Belirti e≈üle≈ümesi
        symptom_matches = sum(1 for symptom in symptoms 
                            if symptom.lower() in str(example).lower())
        score += (symptom_matches / len(symptoms)) * 0.5
        
        return score
    
    def _evaluate_prediction(self, analysis: str, expected_disease: str, 
                           plant_type: str, symptoms: List[str]) -> Dict[str, Any]:
        """Tahmin sonucunu deƒüerlendirir"""
        
        evaluation = {
            "disease_detected": False,
            "symptom_accuracy": 0.0,
            "treatment_relevance": 0.0,
            "confidence_score": 0.0,
            "overall_score": 0.0
        }
        
        # Hastalƒ±k tespiti kontrol√º
        if expected_disease and expected_disease.lower() in analysis.lower():
            evaluation["disease_detected"] = True
        
        # Belirti doƒüruluƒüu
        symptom_accuracy = sum(1 for symptom in symptoms 
                             if symptom.lower() in analysis.lower())
        evaluation["symptom_accuracy"] = symptom_accuracy / len(symptoms)
        
        # Tedavi uygunluƒüu
        treatment_keywords = ["tedavi", "ila√ß", "fungisit", "bakƒ±r", "s√ºlf√ºr", "biyolojik"]
        treatment_matches = sum(1 for keyword in treatment_keywords 
                              if keyword in analysis.lower())
        evaluation["treatment_relevance"] = min(treatment_matches / 3, 1.0)
        
        # G√ºvenilirlik skoru
        if "g√ºvenilirlik" in analysis.lower() or "%" in analysis:
            evaluation["confidence_score"] = 0.8
        else:
            evaluation["confidence_score"] = 0.6
        
        # Genel skor
        evaluation["overall_score"] = (
            evaluation["symptom_accuracy"] * 0.4 +
            evaluation["treatment_relevance"] * 0.3 +
            evaluation["confidence_score"] * 0.3
        )
        
        return evaluation
    
    def run_validation_tests(self) -> Dict[str, Any]:
        """Doƒürulama testleri √ßalƒ±≈ütƒ±rƒ±r"""
        
        if not self.training_data:
            return {"error": "Eƒüitim veri seti y√ºklenmedi"}
        
        print("üß™ Doƒürulama testleri ba≈ülƒ±yor...")
        
        test_cases = [
            {
                "plant_type": "Domates",
                "symptoms": ["Kahverengi lekeler", "Yaprak d√∂k√ºlmesi"],
                "expected_disease": "Erken Yaprak Yanƒ±klƒ±ƒüƒ±"
            },
            {
                "plant_type": "Salatalƒ±k",
                "symptoms": ["Beyaz pudra benzeri leke"],
                "expected_disease": "K√ºlleme"
            },
            {
                "plant_type": "Biber",
                "symptoms": ["K√º√ß√ºk su damlasƒ± lezyonlarƒ±"],
                "expected_disease": "Bakteriyel Leke"
            }
        ]
        
        results = []
        total_score = 0.0
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"Test {i}: {test_case['plant_type']} - {test_case['expected_disease']}")
            
            result = self.train_with_few_shot_learning(
                test_case["plant_type"],
                test_case["symptoms"],
                test_case["expected_disease"]
            )
            
            if result["success"]:
                evaluation = result["evaluation"]
                total_score += evaluation["overall_score"]
                
                test_result = {
                    "test_id": i,
                    "plant_type": test_case["plant_type"],
                    "expected_disease": test_case["expected_disease"],
                    "actual_analysis": result["analysis"][:200] + "...",
                    "evaluation": evaluation,
                    "passed": evaluation["overall_score"] > 0.7
                }
                
                results.append(test_result)
                
                status = "‚úÖ PASS" if test_result["passed"] else "‚ùå FAIL"
                print(f"  {status} - Skor: {evaluation['overall_score']:.2f}")
            else:
                print(f"  ‚ùå HATA: {result['error']}")
        
        # Genel performans hesapla
        avg_score = total_score / len(test_cases) if test_cases else 0.0
        
        validation_summary = {
            "total_tests": len(test_cases),
            "passed_tests": len([r for r in results if r["passed"]]),
            "failed_tests": len([r for r in results if not r["passed"]]),
            "average_score": avg_score,
            "test_results": results,
            "performance_grade": self._get_performance_grade(avg_score)
        }
        
        print(f"\nüìä Doƒürulama Sonu√ßlarƒ±:")
        print(f"Toplam Test: {validation_summary['total_tests']}")
        print(f"Ba≈üarƒ±lƒ±: {validation_summary['passed_tests']}")
        print(f"Ba≈üarƒ±sƒ±z: {validation_summary['failed_tests']}")
        print(f"Ortalama Skor: {avg_score:.2f}")
        print(f"Performans: {validation_summary['performance_grade']}")
        
        return validation_summary
    
    def _get_performance_grade(self, score: float) -> str:
        """Performans skoruna g√∂re not verir"""
        if score >= 0.9:
            return "A+ (M√ºkemmel)"
        elif score >= 0.8:
            return "A (√áok ƒ∞yi)"
        elif score >= 0.7:
            return "B+ (ƒ∞yi)"
        elif score >= 0.6:
            return "B (Orta)"
        elif score >= 0.5:
            return "C (Yeterli)"
        else:
            return "D (Yetersiz)"
    
    def export_training_report(self, output_file: str = "training_report.json"):
        """Eƒüitim raporunu dƒ±≈üa aktarƒ±r"""
        
        report = {
            "training_date": datetime.now().isoformat(),
            "model_info": {
                "name": self.model,
                "api_version": "2023-06-01"
            },
            "dataset_info": {
                "total_examples": len(self.training_data),
                "plant_types": list(set(
                    example["messages"][0]["content"][0]["text"].split("Bitki T√ºr√º: ")[1].split("\n")[0]
                    for example in self.training_data
                    if "Bitki T√ºr√º: " in example["messages"][0]["content"][0]["text"]
                ))
            },
            "performance_metrics": self.performance_metrics,
            "recommendations": self._generate_recommendations()
        }
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ Eƒüitim raporu olu≈üturuldu: {output_file}")
            return True
            
        except Exception as e:
            print(f"Rapor olu≈üturma hatasƒ±: {e}")
            return False
    
    def _generate_recommendations(self) -> List[str]:
        """Model iyile≈ütirme √∂nerileri olu≈üturur"""
        
        recommendations = []
        
        if len(self.training_data) < 10:
            recommendations.append("Daha fazla eƒüitim √∂rneƒüi ekleyin (en az 10)")
        
        if self.performance_metrics["accuracy"] < 0.8:
            recommendations.append("Model doƒüruluƒüunu artƒ±rmak i√ßin daha spesifik prompt'lar kullanƒ±n")
        
        recommendations.append("Farklƒ± bitki t√ºrleri i√ßin √∂zel eƒüitim verileri ekleyin")
        recommendations.append("Mevsimsel ve b√∂lgesel fakt√∂rleri dahil edin")
        recommendations.append("Uzman doƒürulamasƒ± ile veri kalitesini artƒ±rƒ±n")
        
        return recommendations

if __name__ == "__main__":
    # AI Trainer'ƒ± ba≈ülat
    trainer = AITrainer()
    
    # Eƒüitim veri setini y√ºkle
    if trainer.load_training_data():
        print("üöÄ AI Trainer ba≈ülatƒ±ldƒ±!")
        
        # Doƒürulama testleri √ßalƒ±≈ütƒ±r
        validation_results = trainer.run_validation_tests()
        
        # Eƒüitim raporu olu≈ütur
        trainer.export_training_report()
        
        print("\nüéØ Eƒüitim tamamlandƒ±! Model kullanƒ±ma hazƒ±r.")
    else:
        print("‚ùå Eƒüitim veri seti y√ºklenemedi!")
